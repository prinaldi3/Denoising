{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SG vs. CNN Exp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOQa6Jr/mIU6GV/ZkR0L3zv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prinaldi3/Denoising/blob/main/SG_vs_CNN_Exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUUImMt8H7wq"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvdCwbIQws1S"
      },
      "source": [
        "Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QceeRFd0IAqH"
      },
      "source": [
        "!python -m pip install pip==21.0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fZC5ZrJIB1s"
      },
      "source": [
        "!rm -rf xca\n",
        "!git clone https://github.com/maffettone/xca"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO5CQ4AKIDPx"
      },
      "source": [
        "%%bash\n",
        "cd xca\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pY8snuKIDVW"
      },
      "source": [
        "import xca\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from xca.ml.tf_models import build_CNN_encoder_model, build_CNN_decoder_model, VAE_denoising_training, VAE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdjTbuNeBY2G"
      },
      "source": [
        "Preprocessing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMlFjQHYJzwO"
      },
      "source": [
        "from xca.ml.tf_data_proc import build_dataset\n",
        "\n",
        "#these control the degree/intensity of noise\n",
        "log_noise_min= -1 \n",
        "log_noise_max= -.5\n",
        "\n",
        "# Build dataset\n",
        "def preprocess(data, label):\n",
        "    X = tf.cast(data, tf.float32)\n",
        "    X = (X - tf.math.reduce_min(X, axis=0, keepdims=True)) / (\n",
        "        tf.math.reduce_max(X, axis=0, keepdims=True)\n",
        "        - tf.math.reduce_min(X, axis=0, keepdims=True)\n",
        "    )\n",
        "    noisy = tf.cast(data, tf.float32) + tf.random.normal(\n",
        "        data.shape,\n",
        "        stddev=10 ** np.random.uniform(log_noise_min, log_noise_max),\n",
        "        dtype=tf.float32,\n",
        "    )\n",
        "    noisy = (noisy - tf.math.reduce_min(noisy, axis=0, keepdims=True)) / (\n",
        "        tf.math.reduce_max(noisy, axis=0, keepdims=True)\n",
        "        - tf.math.reduce_min(noisy, axis=0, keepdims=True)\n",
        "    )\n",
        "    return {\"X\": X, \"X_noisy\": noisy, \"label\": label}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFOnW6pZc2ON"
      },
      "source": [
        "#change as needed\n",
        "dataset_paths = ['/content/gdrive/MyDrive/tuning_plots_data_9/tfrecords/data.tfrecord']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvZfd_Nab7f5"
      },
      "source": [
        "#Now preprocess guassian data\n",
        "batch_size = 8\n",
        "data,_ = build_dataset(\n",
        "        dataset_paths=dataset_paths,\n",
        "        batch_size=batch_size,\n",
        "        multiprocessing=1,\n",
        "        categorical=True,\n",
        "        val_split=0.0,\n",
        "        data_shape=(500,1),\n",
        "        preprocess=preprocess,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRw62DMIBbkm"
      },
      "source": [
        "Load Model and Plot Comparison "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXZlm2jQc5KT"
      },
      "source": [
        "#Define and load model\n",
        "encoder, last_conv_shape = build_CNN_encoder_model(data_shape=(500,1), latent_dim=100, dense_dims=[], filters=[32, 32, 16], kernel_sizes=[16, 16, 16],  strides=[1, 1, 1], pool_sizes=[1, 1, 1], paddings=[\"same\"]*3, verbose=True)\n",
        "\n",
        "decoder = build_CNN_decoder_model(data_shape=(500,1), latent_dim=100, last_conv_layer_shape=last_conv_shape, filters = [16, 32, 32], kernel_sizes=[16, 16, 16], strides=[1, 1, 1], paddings=[\"same\"]*4, verbose=True)\n",
        "vae = VAE(encoder, decoder, 0.)\n",
        "\n",
        "cnn_checkpoint_path = '/content/gdrive/MyDrive/guassian_denoise_95/training_checkpoints'\n",
        "checkpoint = tf.train.Checkpoint(model=vae)\n",
        "checkpoint.restore(tf.train.latest_checkpoint(cnn_checkpoint_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6DLwcb_c8Ne"
      },
      "source": [
        "from scipy.signal import savgol_filter\n",
        "\n",
        "#Plot a comparison between CNN reconstruction and Savitzky-Golay smoothing\n",
        "for batch in data:\n",
        "  #remove noise from data with CNN\n",
        "  output = vae(batch[\"X_noisy\"], training=False)\n",
        "  X_denoise_CNN = output[\"reconstruction\"][0]\n",
        "\n",
        "  X = batch[\"X\"][0]\n",
        "  X_noisy = batch[\"X_noisy\"][0]\n",
        "\n",
        "  #smooth out data with Savitzky-Golay filter\n",
        "  window_size = 45\n",
        "  poly_degree = 10\n",
        "  deriv = 0\n",
        "  X_noisy = np.reshape(X_noisy, (500,))\n",
        "  X_denoise_SG = savgol_filter(X_noisy, window_size, poly_degree, deriv=deriv) #fit to polynomial of degree 10\n",
        "\n",
        "  label = batch[\"label\"][0]\n",
        "  fig, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "  #Plot reconstructions (as well as raw, true data) on top of one another\n",
        "  ax.plot(X_noisy + 3, label=\"Raw\", color='gray')\n",
        "  ax.plot(X + 2, label=\"True\", color='k')\n",
        "  ax.plot(X_denoise_CNN + 1, 'r', label=\"CNN Denoise\")\n",
        "  ax.plot(X_denoise_SG, 'b', label=\"SG Denoise\")\n",
        "\n",
        "  ax.set_title(\"Comparison of CNN and Savitzky-Golay Denoising (Guassian data)\")\n",
        "  ax.set_xlabel(\"Pixel #\")\n",
        "  ax.set_ylabel(\"Intensity [Arb.]\")\n",
        "\n",
        "  ax.get_yaxis().set_ticks([])\n",
        "  #fig.savefig('/content/gdrive/MyDrive/poster_figs/CNN_SG_comparison_guassian_window45', facecolor='white')\n",
        "  plt.legend()\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}